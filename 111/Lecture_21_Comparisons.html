<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Lecture 21 Comparison</title>
    <link href="https://fonts.googleapis.com/css?family=Kadwa" rel="stylesheet">
    <style>
        /* global variables */
        :root {
            --light-mode-background-color: #F0F4F8;
            --light-mode-h1-color: #191970;
            --light-mode-text-color: #191970;
        }

        body {
            font-family: "Kadwa", Georgia, "Times New Roman", Times, serif;
            line-height: 1.6;
            max-width: 800px;
            margin: auto;
            padding: 20px;
            background-color: var(--light-mode-background-color);
        }

        p {
            white-space: pre-wrap;
            text-align: justify;
            font-size: 30px;
        }

        h1 {
            color: var(--light-mode-h1-color);
            font-size: 40px;
            text-align: center;
        }
    </style>
</head>
<body>
<h1>Lecture 21 Comparison</h1>
<p>
    hey guys, again, this is really awkward. standing in front of a group full of people, I hate this as much as you guys do. so we are once again looking for class rep feedback. we have our meeting on Wednesday, so if you guys could fill in the QR code, it just links to a form. it's all completely anonymous. we don't know who's saying what or whatever. so say whatever you like within reason. thank you so much for all your responses. last time it was great to hear from all of you. and yeah, basically this form, same format as the last one, very quick, very easy to fill out. so, thank you. why is it doing that? okay, fine. well, no, full screen mode today. we'll just go with that, all right? oh, question, possibly I might have got the numbers wrong for this one. this is the lecture I want to talk about, so it's possible that number is wrong. okay, wait, let me double check. this is the one I want to do, right? yes, all right. so what we're going to be doing today is continuing on talking about hypothesis testing for comparing two populations. we'll also talk about how to do confidence intervals as well. so, just like when we did it for one population, we did hypothesis testing and then confidence intervals. after that we'll do the same thing for two populations. okay, so let's sort of look back at what we were doing. that button there, right? so we've. let's just look back our private and public maths test scores, right? so we're evaluating the value of children by their math test scores and we're comparing sort of private school scores versus public school scores. okay, and so the idea was: well, is the average math test score for a public school student different to the average math test score for a private school students? okay, so the the process we went through or the hypothesis test that we did. so we did nope that one. so those were the hypotheses that we compared in this scenario. right, mu one minus mu two is equal to zero. or alternative hypothesis: mu one minus mu two is not equal to zero. so this is most commonly referred to as a two sample t test. so if you hear the phrase two sample t test, what that is, is this comparison or this pair of hypotheses, right, asking ourselves: is there a difference between the average of these two groups? okay, so it's. it's actually which is? it's actually quite a good name. it's quite rare in statistic for the names to be good. they're usually nonsense. this one actually works quite well. right, it is about comparing two samples. i've got two groups, so i collect two samples and i want to compare them. and we do do a t test, or at least we use the t distribution right to compare the two things. one thing that i didn't mention, but i will now: when we were doing it just for one population, so when we had one population and we're doing just for one population, this is called by some people a one sample t test. okay, so if there's just one population, you only collect one sample. that's called a one sample t test. i personally don't tend to use that terminology, but some people do. right, so, two samples, two populations, comparing them with t tests- okay. so what did i want to do? so when we were doing this in excel, one of the things we touched on at the end of class on friday, if you click on data analysis and we scroll down, there are two sample t tests there. okay, there's sort of four options. in a sense, there's a paired two sample for means. oh, that is. that is truly an awful way to call what i think that is. oh, that's awful, we'll do that thursday. yeah, we'll be going through that one. on thursday there's a z test, two sample for means. it's not a thing. no one uses that. don't know why. excel it's excel, does. it's just not a thing, so don't worry about that. okay, so what we've got here are two sample t tests and there's two options: assuming equal variances or assuming unequal variances. okay, so there are two options in excel: equal variances and unequal variances. so the process that we went through, let's see. so is that up there? no, that is not okay. so we did this. do you remember what we did last week? we were comparing two populations. our test statistic was the difference between the sample means and we divide by the standard error, and the standard error looks like this: we've got s1 squared over n1 and s2 squared over n2. okay, so s1 squared, this is the sample variance of population one, and s2 squared is the sample variance of population two. okay, so we've used the two standard deviations or the two sample variances, and the question, or what we've done, is: we've used unequal variances in a sense. right, we haven't assumed these two things are the same thing. okay, what is assuming equal variances? well, how do I want to explain this? what's the idea actually. okay, let's do this quickly. these are the private school summary stats. let's do the same same thing. okay, right, so I've got the private school stats and I have the public school stats. okay, so I've got the mean of the private school, mean of the public school. also got the standard deviation, or the sample standard deviation, of the private school and the sample standard deviation of the public school. okay, so when we did this last week, we made this calculation and we used those two standard deviations on their own. we used 8.88 and 9.43 and plugged them into that equation. okay, what we're going to do is a slightly different approach today. so what does it say? it says: if, for some reason, we want to assume that the variances are equal or, equivalently, the standard deviations are equal, then what we're going to do is use a pooled sample standard deviation. now the formula looks complicated. it's actually relatively straightforward what it is actually doing, right? so here's the basic idea. I have a standard deviation from my private schools of 8.88 standard deviation of my public school of 9.43. if I want to assume that these two populations have the same standard deviation, what do I think the standard deviation is then right, based on my data, or what should I use as it? right, so S1 is 8.88, S2 is 9.43. what I want to do somehow is combine these two things. right, if I'm assuming both populations have the same standard deviation for some mysterious reason, which, just except for the time being, if I'm assuming that's true- I want to sort of combine these two numbers in some way. right, and what I probably want to do is take some sort of average between these two numbers. right, that seems like a reasonable thing to do, right, but I probably don't want to just add the two numbers up and divide by two. right, because on some level, I have 32 observations from private schools and I got a standard deviation of 8.88, got 168 observations from the public schools and got a standard deviation of 9.43. on some level, or whatever, I trust this number more. this seems more important because I've collected this comes from five times as much data as this group. there's five times more public data compared to private data. so if I was going to pick a number between these two numbers as my overall guess, I probably want to pick one closer to 9.43 than 8.88. right, I want a number between those two. pick one closer to the one that I've got more information about the one I'm more confident about. so that's what this formula does. so maybe I'll write it without the square root first: n1 minus 1 s1 squared plus n2 minus 1 s2 squared over n1 plus n2 minus 2. okay, so the formula looks a bit funky, but let me just hack away at it a little bit. so let's pretend the two minus ones and that minus two aren't there. they are, but you know, let's just suppose they're both big numbers, right? if I'm multiplying by 100 or multiplying by 99, whatever, it's more or less the same thing. so let's for now, just for simplicity, forget about the minus one and the minus two. this is what we have. or I could rewrite this like this: I could split it into my two individual bits, like so: and what does this mean? this mean this is exactly the weighted average between S1 squared and S2 squared. okay, so what do I mean by that? well, let's suppose N1 is equal to 50 and N2 was equal to 100. okay, so, first sample: I took 50. second sample: I took 100. I don't know, you might think: okay, I've got twice as much data from the second sample, so I should make that twice as important in some sense, okay. well, so N1 over N1 plus N2 would be 50 over 150. so be a third. N2 over N1 plus N2 would be two thirds, okay. so I have twice as much data in the second population compared to the first one. how the number I put in front of S1 squared and S2 squared. I've got twice as much data for the second population, so I want it to be twice as important in some sense. so what I'll do is I'll take two thirds times S2 squared and I'll take one third times S1 squared and then in some sense I'm using S2 twice as much compared to S1. so I'm taking an average of the two, but rather than averaging half and half, I'm going to average by how important I think each variable is, and when I say important I mean how many observations I have for each of these groups. so that's sort of the explanation of what that function actually does. and then, fancy pants, maths says we have to subtract one everywhere or subtract two on the bottom. and again, trust me. so that is the pooled standard deviation estimate. so let's just do an example. so the pooled standard deviation, what did I say? it's going to be the square root of. so here I've got 32. so 31 times the first standard deviation squared. so N1 is 32. so subtract one 31, multiply by that standard deviation squared, and then I'm going to take 168. is how many observations for the second group? I'm going to subtract one, 167 times that standard deviation squared. and now I realize I need extra brackets and I'm going to divide this by 32 plus 168 minus 2, close that, okay. so just using the formula and the slides, but plugging in the actual values and let's see what we get. so we get 9.346. so what we see is we get. we're trying to, we're, roughly speaking, averaging these two standard deviations, 8.88 and 9.43. we're averaging them, but I've got way more data for population too. so if I'm going to take the average, rather than just taking the middle of those two numbers, I'm going to pick a number that's actually closer towards the one I'm more confident about. so you can see that this 9.34 is quite close. it's closer to 9.43 than 8.88. so that's the idea. if I've got a pooled standard deviation, I just want to take an average of the two in some way and apparently that's the average we're going to take. it's a bit fiddly, but it's a formula we can live with that. oops, don't do that. nope, sorry, forgot that doesn't work, okay. so what does the standard error then become? oh, I wrote it in a confusing way. the standard error is going to be that pooled standard deviation. so this value there, multiplied by one over n1 plus one over n2, all under the same square root, which really, if you rewrite this, is sp squared over n1 plus sp squared over n2. so what's the difference? before we had s1 squared over n1 and s2 squared over n2, when we were assuming unequal variances. all we're doing now, if we're assuming the same, we should use the same value in those two spots. right? if I'm assuming these two things the same, I'm going to use the same value. so that's what we do. we put in the same value. and the question that we just have to ask ourselves is: so what is that same value? and apparently it's. it's this formula here: you just take the average of the two standard deviations, but a weird average, but sort of this weighted average of the two standard deviations, stick them together and then in the standard error we use both of the same values. and then for the hypothesis test, for the t distribution, what's the right degrees of freedom? it's n1 plus n2 minus two. that's just write that down in a cheat sheet formula: n1 plus n2 minus two. okay, so let's just work through this and we'll see how this works. so I've got my pooled standard deviation there: 9.34658. so my test statistic: oops, actually, let's work out the standard error first. so the standard error is the pooled standard deviation times the square root of 1 divided by 32 plus 1 divided by 168, so it's 1.8. so test statistic: it's going to take the same form, but we just use a slightly different formula for the standard error. so we're still going to look at the difference in the two samples means divided by the standard error. so it's still going to be 54.75 minus 52.24. divided by the standard error, so 1.39. so we've got end point is 1.39 and our degrees of freedom is: I take the two sample sizes, add them together and subtract two. so 32 plus 168 minus 2 is 198. so my p value there. oops, so my p value is 0.161. oops, 6, 1. so this one here, the probability of being bigger than 1.39. but then 2 tell. so they multiply it for 2, for us 1.661. so now, since the p value is bigger than 0.5, we do not reject the null hypothesis that the means of the two populations are the same, right. so we haven't. we're not. we're not concluding there's a difference. we're sort of like: okay, no, that reasonably close to each other, so we're not going to reject that null hypothesis. okay, so process is just the same, runs through the same thing, we just use a slightly different formula. I'll have to stop doing that. okay, so that's all fine. oh no, we did that. so the question is, why did I just do this to you? you might have, at the end of last week, you might have been okay, I'm comfortable with this now. and now Hans come along and said: oh yeah, there's another way of doing this and it kind of does the same thing, but not quite the same. so there's a legitimate question of why are there two ways of doing this? why are there two options? and then there's the other question of: well, how do I know which one I should use? so, for the purposes of this class at the very least, if the question says use a pooled variance, then you use a pooled variance or a pooled standard deviation. you use a pooled standard deviation. if the question says do not assume equal variances or do not assume equal standard deviations, use what we did last week. and if the question does not specify which one I want you to use, you can choose either. it's up to you, but that's just for assessment, sort of. if I was doing this in practice or in real life or whatever, what would I do? how do you know which one you should use? so my recommendation- this is a bit of a personal recommendation- if anything is to not do the pooled variance estimate. use the way we did it last week as opposed to this week. why, sort of? if we look at this data or this here with the math starter- standard deviation 8.88, standard deviation 9.43- I mean, okay, fine, they're a bit close. but to me it's a bit weird to look at those two numbers and go, yeah, they're close enough. so I'm going to add an extra assumption, I'm going to assume that they're actually equal and take the average of these two in some way right. to me it's a bit logically. it seems a bit, when you don't have to, you've made an extra assumption that you don't need to actually make. so why make that extra assumption? why assume that they are equal? okay, there are some advantages of using the pooled estimate. what? what sort of the main advantages. so there's a whole bunch of maths that says if the standard deviations are actually the same, if they are the same, then using the pooled standard deviation is the correct thing to do, because maths says that. if you gave me about 10 hours I could explain why, but I don't think anyone wants to hear why, so just trust me. but if there's a whole bunch of mathematical theory that says if the two standard deviations are the same, you should use the pooled estimate, and then it works. and the degrees of freedom that you use for the t distribution is n1 plus n2 minus 2, and that's sort of 100% mathematically good. it all works perfectly. if you remember back to last week when it was like we did the unpooled estimate, we've got two different standard deviations. there's a question of what is the correct degrees of freedom, and I gave you two answers. there was: you take the smaller two sample sizes and subtract one, or use that big horrible formula. which one do you use? is there a right answer? is there a wrong answer? in some sense they're both wrong. they're both approximations and they're not quite correct. there is no correct answer to that question. so in some sense, if you're assuming standard deviations. the method that you use is approximately correct. it's it's very, very close to being completely fine, so don't stress out about it. people use it all the time but the maths behind it's not quite checking out in practice. what difference does it make? let's, let's find out, okay. so let's see two sample assuming equivalences. so we'll do this in excel: variable one: range- private school scores. variable two: range public school scores. put the output here, okay, so here's the two sample t-test, assuming equal variances. so the pool variance is there? test statistic: 1.39. I don't know why- again, there's all these weird things, but we're looking for a two sided test, so we're looking for two tail, apparently, and some think about a p hate excel: 1.66. okay, so that's what we got here: 1.66 and 1.39 as our test stat. so that number and that number there, and that's what we got, assuming equal variances. let's do the same thing, assuming unequal variances, and let's see whether there's any difference or not. here, oh, here, oh, okay, Okay, assuming equal variances. assuming unequal variances. So, assuming equal variances, the test statistic was 1.39.. Assuming unequal variances, the test statistic was 1.448.. Which, but you guys, that's pretty close to the other one. The p-value was 1.0166.. The p-value assuming unequal variances- was 0.154.. Not the same, but pretty close, right? I mean both of them are still above 0.05.. You would end up making the same conclusion. So in practice it won't make much difference most of the time, And that's because, I mean, the standard deviation here is 8.8 and 9.43.. If I use those two individual values or I average them together, it's not going to make much difference because those numbers are all relatively close to each other, right? There's no massive difference between the two. okay, Yeah, Oh, do I not have a slide about this? Oh, Hmm, So I guess I'm writing this. I don't know why I'm putting this in brackets. I'm putting this in quote marks. So here's a rule of thumb that people use. So if I take the variance of the first population and I divide it by the variance of the second population, and that is bigger than two, you must use unequal variances. Basically, what you're asking yourselves is: I've got my two variances from each, or my sample variance from each population. If they're actually just, if one is five and the other one is 800, you might look at that and go: well, I'm pretty sure those numbers are not the same. I should not assume those numbers are the same. I should not assume the standard deviations are the same. If the standard deviation from the first population was 10 and the standard deviation from the second population was 10.2, you'd be like that's basically the same thing. I might want to assume they're the same thing. So a rule of thumb that some people do is take the variances and see whether one is more than twice as big than the other one. right? So I should say all S2 squared over S1 squared is bigger than two. So whichever one is bigger, just look at the ratio between the two. One of them is more than twice as big as the other one. for the variances, I've got 78 for this variance and 88. I would look at those two numbers and go one of them is not twice as big as the other one. All right, if that's the case, I might use equal variances or unequal variances. If they're close-ish, I might use equal variances, and if they're far away from each other, if they're bigger than a factor of two away from each other, I would use unequal variances. This is a rule of thumb. There's no hard and fast rule about this. You just sort of. that's just one of those rules that people use to just decide how to do things. Like I said for this class, I will either specify which one I want you to use and if I don't, then you can choose either, and they will both be fine, All right. does anyone have any questions about that? Okay, so hypothesis testing for two populations done. That took us about no, I have to stop doing that. That took us about three lectures to do hypothesis testing. We've got 12 minutes left and in 12 minutes- because I hate well, hypothesis testing, the worst and confidence was really nice- We'll be able to do confidence intervals in about 12 minutes. That's the hope. All right, so confidence intervals: What was the idea? Think back when we had one population. I sort of said: right, I've got a sample, I've got the average height of 200 people. I asked myself: well, I got the data from, I've got my best guess Based on my sample. the average height is 172 centimeters. How good do I feel about that? or how confident do I feel about that? The confidence interval gave us a way of quantifying that. We sort of, based on the confidence interval, we could say we're 95% sure that the average for the population sits between these two values. What is the analog for comparing two populations? So when we talked about confidence intervals a couple weeks ago- now a week and a half ago, the general idea of a confidence interval is: take the estimate of the thing you're interested in and add or subtract two standard errors. All confidence intervals, more or less, will take this form: Estimate whatever you're interested in, add or subtract two standard errors. So when we were looking at one population mean, we're interested in the population mean. Our best guess for the population mean was the mean of our sample. so X bar Adds, in fact, some T value thing, which is about two, but some T distribution thing, with n minus one degrees of freedom, and the standard error was S over square root of n. So what we did before in our null hypothesis, we're interested in the population mean, mu, and we use X bar as our best guess of the population mean, mu, and then we calculate a confidence interval for X bar based upon mu. Now we're comparing two population means, mu one minus mu two. So what are we interested in? Well, we're really focusing on the difference between mu one and mu two. So what would we use? Well, the sort of natural choice would be: use the sample mean of the first one and subtract the sample mean of the second one, and that would be your best guess or your estimate for what the difference between those two means are. Then we need to add a subtract T thing times the standard error. So that's, on some level, basically it to calculate the confidence interval. because we've talked about what the standard error is in each of these two scenarios and when we did the hypothesis testing I told you what T distribution to use as well. right, If I'm using unequal variances, it's N1, or it's the smaller of N1 or N2, and we subtract one. If I'm assuming equal variances, it's N1 plus N2 minus two. And that's pretty much it, in a sense, right To calculate. we've actually got all the ingredients we need for our confidence interval. So what do I mean? Let's do this for this example here. Okay, so the confidence interval is just going to be. it's just going to be X1 bar minus X2 bar plus or minus. so here I'm using the pooled standard deviation right to calculate my standard error. This is the one we did before. so I used the pooled standard deviation. I assume they're the same. So when I'm assuming they're the same, we're going to use N1 plus N2, minus two degrees of freedom. The same is what we used in the hypothesis test, And we'll take the 97.75 quantile and we'll multiply that by the standard error. So for this example, here we would take that sample mean minus that sample mean, and then I'm going to subtract- oh, I need to find out the 97.5th percentile- So probably 0.975, 198.. It's 1.972.. Like I said, it's a number that's almost always more or less two, So 1.972.. So here I will subtract 1.972 times the standard error, which I conveniently have there from before. And here I'm going to take this mean minus this mean plus 1.972 times the standard error there. So we're 95% confident that the difference between private and public schools- Oh, Let's move this down a bit, All right- We're 95% confident that the difference between private and public schools is between: Oh, Average, Ah. So the difference between these two average math scores are between negative 1.05 and 6.07.. So I can calculate a confidence interval for the difference between the two population means And given everything we did with the hypothesis testing, it's pretty straightforward, right. I know how many degrees of freedom to use, because it's the same as we used in the hypothesis testing. Standard error is the same as well, So we can just plug it in like: so We could also do the same thing, assuming unequal variances. So assuming unequal variances, what would the difference be? Our standard error takes a slightly different form. So, if you remember, a standard error is just the square root of the first variance divided by the number of observations plus the second variance divided by the number of observations. Take the square root of those two things, Get a standard error of 1.73.. It's pretty close to the standard error. assuming unequal variances is 1.8.. Like I said, everything's more or less the same: 1.73.. So I need the t-distribution. I'm going to take the smaller of the two. I've got 32 and 168.. So what degrees of freedom I'm going to use? Take the small of the two, subtract one 31.. So the t-value I need is apparently 2.04.. So my 95% confidence interval lower and my confidence interval upper is just going to be: take that variable. that mean minus. that mean minus 2 times the standard error, Or that value minus, that value plus 2 times the standard error there. So it goes negative 1.02 to 6.36.. So pretty close. Like I said, whichever approach you make, most of the time it will make minimal difference. But there's two ways to do it and you get slightly different answers. Okay, let's leave it there, and I'll see you all on Thursday.
</p>
</body>
</html>
    