<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>026 Distribution</title>
    <link href="https://fonts.googleapis.com/css?family=Kadwa" rel="stylesheet">
    <style>
        /* global variables */
        :root {
            --light-mode-background-color: #F0F4F8;
            --light-mode-h1-color: #191970;
            --light-mode-text-color: #191970;
        }

        body {
            font-family: "Kadwa", Georgia, "Times New Roman", Times, serif;
            line-height: 1.6;
            max-width: 800px;
            margin: auto;
            padding: 20px;
            background-color: var(--light-mode-background-color);
        }

        p {
            white-space: pre-wrap;
            text-align: justify;
            font-size: 30px;
        }

        h1 {
            color: var(--light-mode-h1-color);
            font-size: 40px;
            text-align: center;
        }
    </style>
</head>
<body>
<h1>026 Distribution</h1>
<p>
    Okay, Let's start Today. we're going to talk about random variables. that comes from random experiment, the expectation of a random variable and variance of a random variable, and why do we need it? Okay, And then we talk about distributions in the next lecture. I also want to talk to you about your test and exams, but I will do that after we finish the start. Okay, Remember when I talked about experiment trial outcome in the first lecture of probability, If I toss a coin 10 times, that is my experiment. What is a trial in that experiment? Tossing a coin once And outcome is Yes, Whatever we get when we toss a coin. Now, event is whatever we are interested in. If I'm talking about, how many hits do I get when I toss a coin 10 times, and that is my event, that I'm interested in, And then I count the number of hits when I toss a coin 10 times. That experiment is also called a random experiment because if I toss a coin, before I toss a coin, can I predict what will be my outcome? Can I just can I say that I will be a heads if I toss a coin once? We cannot predict the outcome until and unless we actually perform that experiment. Correct, And that's why it's a random experiment. If we already know what we'll get. if we have two variables, we have information about two variables and we have to find a third variable and there's a proper formula for it, we definitely know what the answer will be. But for these experiments it's a random experiment. We do not know what the outcome will be until unless we actually perform that experiment. Correct, That is a random experiment. A random variable is the outcome of that random experiment. If I roll a die once I can get one. So let's say, some other person rolls a die and gets two, Another one gets a one again, and so on. Someone gets a six. If I have a random experiment and let's say I'm storing all these outcomes in a random variable, x, then what is the sample space of that random variable? That's a symbol for sample space. What are the possible set of outcomes for that random experiment? When I roll a die, what are the possible set of outcomes that can I get for my random variable here from a random experiment? One to six. So I'll have either one, two, three, up to six. That is the set of possible outcomes from my random experiment. If my experiment is, how many number of heads do I get If I toss a coin three times, then what is the possible set of outcomes for that random variable? What's the sample space for that random variable x? If I toss a coin three times, what will be the sample space of my random experiment which has a random variable x? I can either get no head, so zero. We can have three tails. We can have one head and two tails, two heads, three heads as well. Can we get four heads? Why not? You're only tossing a coin three times, so that's your possible set of outcomes for this kind of experiment. If my experiment is that I'm capturing height of students enrolled in Maths 1,, 3, 5,, then that sample space of my random variable x is now. in that case I'm talking about an interval, right? In this case I'm saying x is greater than equal to, let's say, some number- 140 centimeter- and less than equal to 200 centimeter. But that's the sample space of my random variable x, because my experiment is that I'm capturing height for everyone in Maths 1,, 3,, 5,. okay, Do you understand what a random variable is? What is a discrete random variable? Let's say I'm capturing data for number of patients in hospital in a day or your age. Any other example for discrete random variable When you're just talking about exact numbers. so we can have 10 patients in a day. we can have five patients in a day. we cannot have 5.5 patients in a day, right? You can either be 18 years old or 19 or 20, cannot be 19.5.. That's a discrete random variable. You're talking about discrete data, correct? What about continuous random variable? Any examples for a continuous random variable: Height, Height. Height- That's a continuous random variable, because you can be 145 centimeters, 145.5 or any number between a certain interval, right? We're not talking about discrete numbers here, we're talking about continuous numbers. So if your random variable stores discrete data, which is age, certain set, you don't have an interval. You either have 18,, 19,, 20.. When you toss a coin, when you roll a die, you either get 1,, 2,, 3, you cannot get 3.5, right, And so on. So when your random variable stores a discrete data, that is called a discrete random variable. When your experiment has a random variable that captures continuous data, that's a continuous random variable. All right, Is that clear? Now why is this useful? Let's take this example first. If we have an experiment where we're capturing number of heads, if I toss a coin three times- but let's make it even simpler. Toss a coin two times, We're saying possible sample space is 0, 1, 2, 3.. For two times it will be 0, 1, 2, because we're tossing a coin twice. So either we'll have heads, heads, heads, tails, tails, heads and tails, tails. So either we have two heads, one one or no heads at all. Now the point of random variable is to understand: is there a certain number or certain outcome in our sample space which is more likely to occur than the other outcomes? And that is where probability comes into the picture. So whole point of the sample space here is: we have an experiment, we have a set of possible outcomes and then we assign probabilities to those possible outcomes to check If there is any outcome which is more likely to occur than some other outcomes in the sample space. Okay, In this case, if you just look at the sample space, you can see that one has a higher probability, one is more likely to occur. You can get more one head scenario than these two scenarios here. If you keep repeating this experiment, if I keep tossing a coin twice, I will see more ones than 0 for two heads. Correct, That's the whole point of random variable. Now, when we assign probabilities to these outcomes. if I'm saying: what is the probability that my random variable X, capital X, is equal to a certain outcome? small x. This is what we're trying to find. right? That's the theoretical way of writing it. We're basically saying x is my random variable from my experiment, capital X and all the possible outcomes here are stored as small x, So that small x can be 0, can be 1, can be 2 for this experiment here, Right? So I can either write: probability of X equals 0, if I'm trying to find the probability of 0, probability of X equals 1, probability of X equals 2.. Small x is all the possible outcomes. It's a variable where we basically put all the outcomes in a random variable. You understand this. Your random variable, your random variable, is capital X. All the possible outcomes in the random variable are basically small x are stored in variable. small x- Clear. Another way of writing this is P- capital X of 0. Theoretically it's P, capital X of small x. If I'm saying probability of 1, then that's how you write it. This is also called a probability mass function. Now here we're going to go a little more theoretical, Also written as PMF. So I'm saying I have a random experiment and there is an X variable, a capital X variable, which is my random variable that has all these possible set of outcomes. PMF of 0 is probability of X equals 0.. PMF of 1 is probability of X equals 1.. PMF of 2 is probability of X equals 2.. What is the probability of getting two heads in this scenario? What is the probability of 2? 1 over 4? Right. What is the probability of 1? Is that only 1 or Just 1.. 1 over 4? Yeah. so let's just be consistent. So I'll just write it as 2 over 4,, okay. And what is the probability of 0? 1 over 4.. Now, if I draw that in a distribution form, X-axis is all the values in your random variable, X, all the possible outcomes in your random variable, and Y-axis is your PMF. So X equals PX of X. OK, So in this scenario, in this experiment, how many possible outcomes do we have in our variable X? We only have 0,, 1, and 2.. So I'm saying 0,, 1, 2, and I want to plot the probabilities of these individual outcomes in my experiment. Let's say that is 1 over 4,, this is 2 over 4.. 0 has 1 over 4 probability, so that 1 is 2 over 4, 2 is 1 over 4.. We are drawing a distribution that is called a probability distribution. It basically plots all the individual probabilities of all the possible outcomes in your random variable x And y-axis is your PMF. it basically says: probability of 0 is this probability of 1, probability of 2.. And that is your probability distribution. Now your x variable. is this a discrete random variable or a continuous random variable? Discrete, Discrete, Discrete. So this is also called a discrete probability distribution. If your random variable is a continuous random variable, then the distribution will be a continuous probability distribution. In this case we're dealing with a discrete random variable, hence a discrete probability distribution. In your- for this paper, you only- we only discussed discrete probability distributions. okay, Is this clear? If I add all the individual probabilities that are given in the question here, this is my experiment. so that's basically all the possible outcomes in my experiment. If I add the probability of 0 for that random variable, x, probability of 1 plus probability of 2, these are all the possible outcomes in my random variable for that experiment. right, It will change for different experiments. What will that add up to One One? We're basically saying: sum of all possible outcomes in an experiment will always add up to one Sum of the probabilities, of all the possible outcomes- and we discussed that in the first lecture of probability. When you have all the possible outcomes, when you have all the possible outcomes, when you add them, you will always get 1, 100%. So when you add the probabilities, you will always get 1.. Clear Any questions so far? Okay, let's take this scenario: Experiment is rolling a six-sided die. PMF for this function, Px of x, a random variable, is capital X and all possible outcomes are stored in small x. So this can also be written as probability of capital X is equal to small x. Is this clear, Okay? So theoretically, we write PMF like this: If we are rolling a die, what are all the possible outcomes? What is the sample space for my random experiment, x? We are rolling a six-sided die, so it will be 1,, 2, up to 6,, right? And all these outcomes have an equal probability: 1 over 6, correct? So we're saying if x is equal to 1, up to 6,, 1,, 2,, 3,, 4,, 5, 6, probability of PMF will be 1 over 6. Zero, otherwise. That's how you write a PMF function, theoretically, Okay. So if the question is: write a PMF, that's how you write a PMF. Now, if I've mentioned that, if you sum the probabilities of all the possible outcomes in an experiment, it will add up to 1.. If I add the probability of 1,, 2,, 3, up to 6- in this case, because these are all the possible outcomes- probability of 1,, 2, up to 6 should add up to 1.. So basically saying 1 over 6, 1 over 6 plus 1 over 6 should add up to 1, because it will be 6 over 6, right? Do you understand this term here? Small x belongs to sample space of x. If I'm saying small x belongs to sample space of x, what does that mean? Is it in sample space? I'm saying if- sorry, can you repeat that again? Can you repeat that again? Is it in sample space of Sample space of Of x? Yes, that's correct, That's my sample space and I'm saying: any value, small x- is part of my sample space, x here, So that small x can be 1,, 2, up to 6, cannot be any other value for that experiment. So we're basically just defining a set limit for our experiment. Okay, Yeah, So you're saying small x is a part of our sample set. Yeah, So small x is- let's just say we have small x and we're just adding that value. We're saying small x is 1, small x is 2, or 6.. So that's basically all the outcomes in that variable. So we first take 1,, so x, small x is 1.. So we're trying: what is the probability of 1? Probability of 2, small x is 2, like that. all right, That is also a discrete probability distribution because x-axis is your random variable and y-axis is your PMF. So this is a discrete probability distribution. It's basically a uniform distribution because the probabilities of all the outcomes are basically the same. So that's a uniform distribution. Let's talk about the expectation of a random variable. There are different ways to summarize a random variable. We can use expectation and also variance of a random variable. The whole point of expectation is to find what is the average value of a random variable when you keep doing that experiment again and again, and again. And this is basically used in gambling problems. That's where this topic came from. So it's useful in some scenarios. In some scenarios it won't make sense, but it's also useful to see what the trend is when you do that experiment in the long run. Now let's read this question. The question is: is a particular game a good investment? Suppose a game's possible winnings can be modeled by a discrete random variable w with PMF provided here. Basically saying, probability of losing a dollar minus 1 is 0.75.. Probability of winning a dollar is 0.2.. Probability of winning $10 is 0.05.. In this case we have a random variable w. It doesn't have to be always x, So we have a random variable w. What is the sample space of that random variable? Yeah, negative: 1, 1, 10.. Is there anything wrong here? No, no, That is the sample space of a random variable. And the question is: is this worthwhile to play? Is this game worthwhile to play? in the long run, If we keep playing this game, you either win a dollar, lose a dollar or win $10.. But if you keep playing this game, is it profitable or not? This is a simulation that run for using RStudio, so you don't have to worry about that software. But if you just increase the count of games at some point you will see there is a threshold. Right, If you play that game once, play that game twice, 20 times, 40 times, after a certain point you will reach that threshold. So we're basically giving you a long run average. The expectation value is basically giving you an average. What happens if you keep playing this game and you have certain probabilities involved? What will be that average value that you will get when you keep playing this game for n number of times. Right? And how do you find that expectation value? If you have to find the expectation of a random variable x, that is basically sum of all the outcomes in the sample space x, You take that small x multiplied by probability of that small x. So for this example, if we just take this example here, we're saying a sample space is 1,, 2, up to 6.. Correct, We're saying we take all the values that are in the sample space which is 1 to 6.. We multiply 1 with the probability of 1 plus 2, multiplied by the probability of 2 plus so on, and we go up to 6 multiplied by probability of 6.. So our jump here is up to the last value of the sample space for a random variable. Right, This is what this means. X belongs to the sample space and we add that value, that outcome, multiplied by the probability of that individual outcome. That will give you an expectation of a random variable x. It is also called the mean of the distribution. If these are your distributions, let's say the first scenario here is a uniform distribution. Expectation is basically the mean of this particular distribution. So it will be somewhere between three to four. You can just visualize the average just from the distribution here. In this case it's a skewed distribution, So your mean will be somewhere here, because obviously most of the values are between 0 to 2.. So the expectation value will be somewhere between 0 to 2.. What do you think for this scenario here? This is a bimodal distribution. You have two modes, right? So your mean will be skewed towards the bigger distribution. So it will be somewhere here. And the last scenario here is called a normal distribution. Shouldn't touch the limits here, but the mean will be basically at the center. So that's the expectation of the distribution, because it's a symmetric distribution here. right, So you can visualize the expectation of the distribution. but in some scenarios like these, when you have some probabilities associated with it, you can just use the formula to estimate the expected value of the random variable. Can you calculate that expected value for this random variable, w? We have to find expectation of a random variable, w. So that means summation of small w that belongs to the sample space of w, Small w, the probability of all those possible outcomes. Do you want to try this? Try finding the expectation of this for this question. We want to check if this game is profitable in the long run or not. So we will find the average earnings in this case. Come on, if not, Let's see Dot. The next one is still Mont treelousis İşte. Thank you. What's the answer? So we have to first open this summation term. here We're basically talking about multiplication of all the possible outcomes and their probability. But we have to sum up for all the possible outcomes here. So we're basically saying, first of W is minus 1, multiplied by probability of minus 1, which is 0.75.. That's one set plus. next jump is 1, 1 multiplied by 0.2 plus that. So this will be minus 0.75 plus 0.2.. What is this? Minus 0.05.. So the question is: is this game profitable in the long run? You're losing 5 cents in every game on average, basically. So this game, based on the probability is assigned to each scenario here, is not profitable. That is the expected value of your random variable for this scenario, which is minus 0.05.. Is this clear? Now, instead of E, W, if suppose I have to find E, W square, And I'll tell you why this is important. That is basically the same thing, but we just change: instead of W we use W square, and that remains the same. It is just another function in the expectation term, right? So if expected value of W square, if that's what we have to find, it's basically small W square multiplied by the probability of that particular outcome. So only difference here will be minus 1 square multiplied by probability of minus 1, which is 0.75, plus 1 square multiplied by probability of 1, which is 0.05, which is 0.2, plus 10 square multiplied by probability of 10, which is 0.05.. What is the answer? Solve this: Minus 0.75.. Minus 0.75 by 5.95.. Is that 5.95?? That is the expectation of W square, where W is your random variable. Now, this term is useful when you have to find the variance of a random variable. Variance of a random variable basically tells you how spread out your random variable is from the mean right. Expectation gives you the average of that random variable and variance gives you the spread of that random variable from the average from the expectation term. That is the definition of variance. but this is the simplest form to calculate variance by hand. So we'll be using this formula here, the easier one. To calculate the variance of a random variable, W, you have to find expectation of W square. In this case we're finding the variance of X. that's why it's expectation of X square In our question. random variable is W, correct, Minus the expectation of W whole square. That's how you'll find the variance of your random variable W and that's why we need expectation of W square. Expectation of W square in this case was 5.95 minus expectation of W was minus 0.05 whole square. What is the answer? You've calculated this right. Solve this: 0.0025, 5.95, should be approximately 5.95.. I will give you 5.947, something. Can you test? what's the answer? So it's 5.95 minus 0.0025, which is You have calculated right. So when you subtract this is approximately 5.95? Yeah, Approximately it is 5.95, because that wasn't a much bigger change. change the variance. What is standard deviation of that random variable W? then If we have a variance, then standard deviation is Square root, Square root of variance. So square root of 5.95 is: Use your calculator: Two point, Two point, Square root of 5.95.. Don't you have homes, Sorry? 2.439.. 2.439, so approximately 2.44, right, That's the standard deviation of your random variable W. So what we are saying in the question is: the expected value of that experiment is minus 0.05.. So in the long run you will lose $0.05 in every game, right, And with the variance here it tells, with the standard deviation value. here we can say that the limits will differ by $2.44 in every game. So every game, on average you will lose $0.05, and that outcome will differ by $2.44 on both ends. Clear, Clear, Any questions? Okay, All right, I have to talk to you about your test. If your test is next Friday, I will upload a notice by tomorrow. Everything from week 7 to week 9 will be included in your test. so everything from relations to counting theory up to handshake theorem- Right, So it covers pigeonhole principle, handshake theorem, permutation combinations, everything. Now I use all your practice questions or your previous year's questions in the lecture, so I prefer to solve the questions with you guys. So I've already used all the questions in the lectures here. so I will not be providing any other test material for you to practice, Because if you practice your test questions, practice questions and all the questions that we have solved in the lecture, that they are more than enough for your tests. So you will not be getting any other separate practice sheet because I will use everything in your lectures, Right? Um, calculators are not allowed. So if you have any probability question, you can leave it in fraction form. Or if you're dealing with, like, permutation questions and if you have something like two to the power of three or something, you just leave it up to that point, It's fine. At any point, you need to use a calculator, it's okay for you. You can just leave the thing as it is. We will not deduct your marks, Okay, But as long as you provide all your working, then we know that you know the answer. Right? Any questions regarding your tests or exams: Your tests will be conducted in two rooms because clearly this room is not enough to accommodate all of you, But I will give you more information on who will be in which room in the test notice, Right? I'll see you on Friday.
</p>
</body>
</html>
    